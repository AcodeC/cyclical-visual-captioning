## Learning to Generate Grounded Visual Captions without Localization Supervision
<img src="teaser/pytorch-logo-dark.png" width="10%"> [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This is the PyTorch implementation of our paper:

**Learning to Generate Grounded Visual Captions without Localization Supervision**<br>
[__***Chih-Yao Ma***__](https://chihyaoma.github.io/), [Yannis Kalantidis](https://www.skamalas.com/), [Ghassan AlRegib](https://ghassanalregib.info/), [Peter Vajda](https://sites.google.com/site/vajdap), 
[Marcus Rohrbach](https://rohrbach.vision/), [Zsolt Kira](https://www.cc.gatech.edu/~zk15/)<br>

[[arXiv](https://arxiv.org/abs/1906.00283)] [[GitHub](https://github.com/chihyaoma/cyclical-visual-captioning)] [Project (coming soon)]

<p align="center">
<img src="teaser/concept.png" width="100%">
</p>

## Code coming soon! Please stay tuned.
